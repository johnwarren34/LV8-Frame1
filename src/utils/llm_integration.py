import_openai  class_LLMIntegration: def___init__(self,_api_key): self.api_key_=_api_key openai.api_key_=_self.api_key  def_query_gpt(self,_prompt,_model="gpt-4",_max_tokens=100): """Query_GPT-based_models_and_return_the_response.""" try: response_=_openai.ChatCompletion.create( model=model, messages=[{"role":_"user",_"content":_prompt}], max_tokens=max_tokens, ) return_response["choices"][0]["message"]["content"].strip() except_Exception_as_e: print(f"Error_querying_LLM:_{e}") return_None  Example_usage if___name___==_"__main__": llm_=_LLMIntegration(api_key="your-openai-api-key") response_=_llm.query_gpt("What_is_the_capital_of_France?") print(f"LLM_Response:_{response}")